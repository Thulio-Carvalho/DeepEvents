{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import create_model\n",
    "nn4_small2 = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nn4_small2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn4_small2_pretrained = create_model()\n",
    "nn4_small2_pretrained.load_weights('weights/nn4.small2.v1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "from align import AlignDlib\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "def load_image(path):\n",
    "    img = cv2.imread(path, 1)\n",
    "    # OpenCV loads images with color channels\n",
    "    # in BGR order. So we need to reverse them\n",
    "    return img[...,::-1]\n",
    "\n",
    "alignment = AlignDlib('models/landmarks.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os.path\n",
    "\n",
    "class IdentityMetadata():\n",
    "    def __init__(self, base, name, file):\n",
    "        # dataset base directory\n",
    "        self.base = base\n",
    "        # identity name\n",
    "        self.name = name\n",
    "        # image file name\n",
    "        self.file = file\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.image_path()\n",
    "\n",
    "    def image_path(self):\n",
    "        if (self.name == None):\n",
    "            return os.path.join(self.base, self.file)\n",
    "        return os.path.join(self.base, self.name, self.file)\n",
    "\n",
    "def load_metadata(path, is_classified):\n",
    "    metadata = []\n",
    "    for i in os.listdir(path):\n",
    "        if is_classified:\n",
    "            for f in os.listdir(os.path.join(path, i)):\n",
    "                # Check file extension. Allow only jpg/jpeg' files.\n",
    "                ext = os.path.splitext(f)[1]\n",
    "                if ext == '.jpg' or ext == '.jpeg':\n",
    "                    metadata.append(IdentityMetadata(path, i, f))\n",
    "        else: \n",
    "            ext = os.path.splitext(i)[1]\n",
    "            if ext == '.jpg' or ext == '.jpeg':\n",
    "                metadata.append(IdentityMetadata(path, None, i))\n",
    "            \n",
    "    return np.array(metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = load_metadata('Batch_Images', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import string\n",
    "\n",
    "FACES_DIR = './Batch_Images/Faces/'\n",
    "LABELED_FACES_DIR = './Batch_Images/Labeled_Faces/'\n",
    "BATCH_LABELED_FACES_DIR = './Batch_Images/Batch_Labeled_Faces/'\n",
    "\n",
    "def generate_random_hex(path):\n",
    "    letters = string.hexdigits\n",
    "    rand_name = ''.join(random.choice(letters) for i in range(10))\n",
    "    \n",
    "    if (rand_name + '.jpg') in os.listdir(): return generate_random_hex() \n",
    "\n",
    "    return rand_name\n",
    "    \n",
    "    \n",
    "def save_image(img, path = FACES_DIR, image_name = '', extension = '.jpg'):\n",
    "    try:\n",
    "        os.listdir(path)\n",
    "    except FileNotFoundError as e:\n",
    "        os.mkdir(path)\n",
    "    \n",
    "    if path[-1] != '/': path = path + '/'\n",
    "        \n",
    "    if image_name == '':\n",
    "        image_name = generate_random_hex(path)\n",
    "        \n",
    "    full_img_name = image_name + extension\n",
    "    full_path = path + full_img_name\n",
    "    \n",
    "    if (not cv2.imwrite(full_path, img[...,::-1])):\n",
    "        raise Exception('Image could not be written')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from progressbar import ProgressBar\n",
    "\n",
    "progress = ProgressBar(len(metadata))\n",
    "progress.start()\n",
    "\n",
    "for i, m, in enumerate(metadata):\n",
    "    \n",
    "    original = load_image(m.image_path())\n",
    "    bounding_boxes = alignment.getAllFaceBoundingBoxes(original) \n",
    "    \n",
    "    if len(bounding_boxes) > 0:\n",
    "                          \n",
    "        for bb in bounding_boxes:\n",
    "            aligned_face = alignment.align(96, original, bb, landmarkIndices=AlignDlib.OUTER_EYES_AND_NOSE)\n",
    "            ## Maybe change to send to specific folder\n",
    "            save_image(aligned_face)\n",
    "        \n",
    "    progress.update(i)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_labels = load_metadata(LABELED_FACES_DIR, True)\n",
    "metadata_faces = load_metadata(FACES_DIR, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from progressbar import ProgressBar\n",
    "\n",
    "def generate_embedding(metadata):\n",
    "    \n",
    "    num_faces = len(metadata)\n",
    "    progress = ProgressBar(num_faces)\n",
    "    progress.start()\n",
    "\n",
    "    embedded = np.zeros((num_faces, 128))\n",
    "\n",
    "    for i, m in enumerate(metadata):\n",
    "        img = load_image(m.image_path())\n",
    "        img = (img / 255.).astype(np.float32)\n",
    "        embedded[i] = nn4_small2_pretrained.predict(np.expand_dims(img, axis=0))[0]\n",
    "        progress.update(i)\n",
    "    \n",
    "    return embedded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_embedded = generate_embedding(metadata_labels)\n",
    "faces_embedded = generate_embedding(metadata_faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_mapper = {}\n",
    "\n",
    "for embedding, metadata in zip(label_embedded, metadata_labels):\n",
    "    embedding_mapper[embedding.tobytes()] = metadata    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "NAME_URL = 'https://api.namefake.com/'\n",
    "\n",
    "def generate_random_name():\n",
    "    gen = lambda: requests.get(NAME_URL, verify = False).json()['name']\n",
    "    \n",
    "    rand_name = gen()\n",
    "    rand_name = rand_name.replace(' ', '')\n",
    "\n",
    "    return rand_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "new_name = {}\n",
    "\n",
    "for m in embedding_mapper.values():\n",
    "    if m.name not in new_name:\n",
    "        rand_name = generate_random_name()\n",
    "        while rand_name in new_name.values():\n",
    "            rand_name = generate_random_name()\n",
    "        new_name[m.name] = rand_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f_emb in faces_embedded:\n",
    "    if f_emb.tobytes() in embedding_mapper:\n",
    "        ## TODO verify if imgs that are not in are faces\n",
    "        m = embedding_mapper[f_emb.tobytes()]\n",
    "        img = load_image(m.image_path())\n",
    "        end_path = BATCH_LABELED_FACES_DIR + new_name[m.name]\n",
    "        save_image(img, end_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "metadata_faces = load_metadata(BATCH_LABELED_FACES_DIR, True)\n",
    "np.random.shuffle(metadata_faces)\n",
    "embedded = generate_embedding(metadata_faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance(emb1, emb2):\n",
    "    return np.sum(np.square(emb1 - emb2))\n",
    "\n",
    "def show_pair(idx1, idx2):\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.suptitle('Distance = %.2f' % (distance(embedded[idx1], embedded[idx2])))\n",
    "    plt.subplot(121)\n",
    "    plt.imshow(load_image(metadata_faces[idx1].image_path()))\n",
    "    plt.subplot(122)\n",
    "    plt.imshow(load_image(metadata_faces[idx2].image_path()));    \n",
    "    \n",
    "def show_pair_name(img_name1, img_name2):\n",
    "    for i, m in enumerate(metadata_faces):\n",
    "        if m.file == img_name1:\n",
    "            idx1 = i\n",
    "        if m.file == img_name2:\n",
    "            idx2 = i\n",
    "    show_pair(idx1, idx2) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is the best threshold for the verification problem (Distance Treshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "distances = [] # squared L2 distance between pairs\n",
    "identical = [] # 1 if same identity, 0 otherwise\n",
    "\n",
    "num = len(metadata_faces)\n",
    "\n",
    "for i in range(num - 1):\n",
    "    for j in range(1, num):\n",
    "        distances.append(distance(embedded[i], embedded[j]))\n",
    "        identical.append(1 if metadata_faces[i].name == metadata_faces[j].name else 0)\n",
    "        \n",
    "distances = np.array(distances)\n",
    "identical = np.array(identical)\n",
    "\n",
    "thresholds = np.arange(0.3, 1.0, 0.01)\n",
    "\n",
    "f1_scores = [f1_score(identical, distances < t) for t in thresholds]\n",
    "acc_scores = [accuracy_score(identical, distances < t) for t in thresholds]\n",
    "\n",
    "opt_idx = np.argmax(f1_scores)\n",
    "# Threshold at maximal F1 score\n",
    "opt_tau = thresholds[opt_idx]\n",
    "# Accuracy at maximal F1 score\n",
    "opt_acc = accuracy_score(identical, distances < opt_tau)\n",
    "\n",
    "# Plot F1 score and accuracy as function of distance threshold\n",
    "plt.plot(thresholds, f1_scores, label='F1 score');\n",
    "plt.plot(thresholds, acc_scores, label='Accuracy');\n",
    "plt.axvline(x=opt_tau, linestyle='--', lw=1, c='lightgrey', label='Threshold')\n",
    "plt.title('Accuracy at threshold ' + str(opt_tau) + ' = ' + str(opt_acc))\n",
    "plt.xlabel('Distance threshold')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distance distributions of positive and negative pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_pos = distances[identical == 1]\n",
    "dist_neg = distances[identical == 0]\n",
    "\n",
    "plt.figure(figsize=(12,4))\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.hist(dist_pos)\n",
    "plt.axvline(x=opt_tau, linestyle='--', lw=1, c='lightgrey', label='Threshold')\n",
    "plt.title('Distances (pos. pairs)')\n",
    "plt.legend();\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.hist(dist_neg)\n",
    "plt.axvline(x=opt_tau, linestyle='--', lw=1, c='lightgrey', label='Threshold')\n",
    "plt.title('Distances (neg. pairs)')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face recognition - with KNN or an SVM\n",
    "\n",
    "70% used for training  \n",
    "30% for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# randomized = [(metadata_faces[i], embedded[i]) for i in range(len(metadata_faces))]\n",
    "# randomized = np.random.shuffle([(metadata_faces[i], embedded[i]) for i in range(len(metadata_faces))])\n",
    "# np.random.shuffle(randomized)\n",
    "\n",
    "targets = np.array([m.name for m in metadata_faces])\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(targets)\n",
    "\n",
    "# Numerical encoding of identities\n",
    "y = encoder.transform(targets)\n",
    "\n",
    "pivot = len(metadata_faces) * 0.3\n",
    "#test_idx = np.array([True if i < pivot else False for i in range(len(randomized))])\n",
    "#train_idx = np.array([not v for v in test_idx])\n",
    "\n",
    "test_idx = np.arange(metadata_faces.shape[0]) < pivot\n",
    "train_idx = np.arange(metadata_faces.shape[0]) >= pivot\n",
    "# embedded = np.array([e for _, e in randomized])\n",
    "\n",
    "# 50 train examples of 10 identities (5 examples each)\n",
    "X_train = embedded[train_idx]\n",
    "# 50 test examples of 10 identities (5 examples each)\n",
    "X_test = embedded[test_idx]\n",
    "\n",
    "y_train = y[train_idx]\n",
    "y_test = y[test_idx]\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=1, metric='euclidean')\n",
    "svc = LinearSVC()\n",
    "\n",
    "knn.fit(X_train, y_train)\n",
    "svc.fit(X_train, y_train)\n",
    "\n",
    "y_pred_knn = knn.predict(X_test)\n",
    "acc_knn = accuracy_score(y_test, y_pred_knn)\n",
    "y_pred_svc = svc.predict(X_test)\n",
    "acc_svc = accuracy_score(y_test, y_pred_svc)\n",
    "\n",
    "f1_knn = f1_score(y_test, y_pred_knn, average='weighted')\n",
    "f1_svc = f1_score(y_test, y_pred_svc, average='weighted')\n",
    "\n",
    "print('KNN accuracy = ' + str(acc_knn) + ' , SVM accuracy = ' + str(acc_svc))\n",
    "print('KNN f1 score weighted = ' + str(f1_score(y_test, y_pred_knn, average='weighted')) +\n",
    "      ' , SVM f1 score weighted = ' + str(f1_score(y_test, y_pred_svc, average='weighted')))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "# Suppress LabelEncoder warning\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def show_prediction(example_idx):\n",
    "    plt.figure()\n",
    "    example_image = load_image(metadata[test_idx][example_idx].image_path())\n",
    "    example_prediction = knn.predict([embedded[test_idx][example_idx]])\n",
    "    example_identity = encoder.inverse_transform(example_prediction)[0]\n",
    "\n",
    "    plt.imshow(example_image)\n",
    "    plt.title('Recognized as ' + str(example_identity));\n",
    "    \n",
    "def show_predictions(indexes):\n",
    "    plt.figure(figsize=(16,16))\n",
    "    \n",
    "    for i, idx in enumerate(indexes[:16]):\n",
    "        example_image = load_image(metadata_faces[test_idx][idx].image_path())\n",
    "        example_prediction = knn.predict([embedded[test_idx][idx]])\n",
    "        example_identity = encoder.inverse_transform(example_prediction)[0]\n",
    "\n",
    "        plt.subplot(4,4,i+1)\n",
    "        plt.imshow(example_image)\n",
    "        plt.title('A:' + str(example_identity) + ' R:' + metadata_faces[test_idx][idx].name)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_predictions(range(10,26))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missclassified images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_pairs = []\n",
    "\n",
    "for i, item in enumerate(y_pred_knn):\n",
    "    if item != y_test[i]:\n",
    "        error_pairs.append(i)\n",
    "        \n",
    "print(error_pairs)\n",
    "\n",
    "show_predictions(error_pairs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "X_embedded = TSNE(n_components=2).fit_transform(embedded)\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "\n",
    "for i, t in enumerate(set(targets)):\n",
    "    idx = targets == t\n",
    "    plt.scatter(X_embedded[idx, 0], X_embedded[idx, 1], label=t)   \n",
    "\n",
    "plt.legend(bbox_to_anchor=(1, 1));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
